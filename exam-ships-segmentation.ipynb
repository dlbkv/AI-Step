{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":8290790,"sourceType":"datasetVersion","datasetId":4925026}],"dockerImageVersionId":30698,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"source":"<a href=\"https://www.kaggle.com/code/dlbkvv/exam-ships-segmentation?scriptVersionId=178618194\" target=\"_blank\"><img align=\"left\" alt=\"Kaggle\" title=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"></a>","metadata":{},"cell_type":"markdown"},{"cell_type":"code","source":"!pip install -q segmentation-models-pytorch","metadata":{"execution":{"iopub.status.busy":"2024-05-19T21:58:14.569923Z","iopub.execute_input":"2024-05-19T21:58:14.570272Z","iopub.status.idle":"2024-05-19T21:58:30.955796Z","shell.execute_reply.started":"2024-05-19T21:58:14.570243Z","shell.execute_reply":"2024-05-19T21:58:30.954867Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"^C\n\u001b[31mERROR: Operation cancelled by user\u001b[0m\u001b[31m\n\u001b[0m","output_type":"stream"}]},{"cell_type":"code","source":"!pip install -q torchsummary","metadata":{"execution":{"iopub.status.busy":"2024-05-19T21:58:30.957842Z","iopub.execute_input":"2024-05-19T21:58:30.958135Z","iopub.status.idle":"2024-05-19T21:58:32.886282Z","shell.execute_reply.started":"2024-05-19T21:58:30.958108Z","shell.execute_reply":"2024-05-19T21:58:32.885342Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"^C\n\u001b[31mERROR: Operation cancelled by user\u001b[0m\u001b[31m\n\u001b[0m","output_type":"stream"}]},{"cell_type":"code","source":"import numpy as np \nimport pandas as pd \nimport torch\nimport os\nfrom torchvision import transforms\nfrom sklearn.model_selection import train_test_split\nfrom PIL import Image\nfrom torch.utils.data import Dataset, DataLoader\nimport matplotlib.pyplot as plt\nimport segmentation_models_pytorch as smp\nfrom segmentation_models_pytorch.encoders import get_preprocessing_fn\nfrom torchsummary import summary\nfrom segmentation_models_pytorch.losses import DiceLoss\nfrom segmentation_models_pytorch import DeepLabV3Plus\nimport torchmetrics\n\ndevice = 'cuda' if torch.cuda.is_available() else 'cpu'","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-05-19T21:58:32.88779Z","iopub.execute_input":"2024-05-19T21:58:32.888159Z","iopub.status.idle":"2024-05-19T21:58:34.443541Z","shell.execute_reply.started":"2024-05-19T21:58:32.888129Z","shell.execute_reply":"2024-05-19T21:58:34.440027Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stderr","text":"\nKeyboardInterrupt\n\n","output_type":"stream"}]},{"cell_type":"code","source":"df = pd.read_csv('/kaggle/input/itstep-exam2/ship_segmentations.csv')\nimg_dir = '/kaggle/input/itstep-exam2/ship_images'","metadata":{"execution":{"iopub.status.busy":"2024-05-19T21:58:34.444524Z","iopub.status.idle":"2024-05-19T21:58:34.444887Z","shell.execute_reply.started":"2024-05-19T21:58:34.44472Z","shell.execute_reply":"2024-05-19T21:58:34.444734Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.head()","metadata":{"execution":{"iopub.status.busy":"2024-05-19T21:58:34.446692Z","iopub.status.idle":"2024-05-19T21:58:34.447026Z","shell.execute_reply.started":"2024-05-19T21:58:34.446863Z","shell.execute_reply":"2024-05-19T21:58:34.446877Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.describe()","metadata":{"execution":{"iopub.status.busy":"2024-05-19T21:58:34.448692Z","iopub.status.idle":"2024-05-19T21:58:34.449012Z","shell.execute_reply.started":"2024-05-19T21:58:34.448851Z","shell.execute_reply":"2024-05-19T21:58:34.448864Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.info()","metadata":{"execution":{"iopub.status.busy":"2024-05-19T21:58:34.450588Z","iopub.status.idle":"2024-05-19T21:58:34.450911Z","shell.execute_reply.started":"2024-05-19T21:58:34.450754Z","shell.execute_reply":"2024-05-19T21:58:34.450768Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"count_ships_df = df.groupby('ImageId').count()\ncount_ships_df","metadata":{"execution":{"iopub.status.busy":"2024-05-19T21:58:34.452051Z","iopub.status.idle":"2024-05-19T21:58:34.45238Z","shell.execute_reply.started":"2024-05-19T21:58:34.452204Z","shell.execute_reply":"2024-05-19T21:58:34.452217Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"count_img_to_ships = {}\nmax_ships_img = count_ships_df['EncodedPixels'].max()\nfor i in range(0, max_ships_img +1):\n    temp_count = count_ships_df[count_ships_df['EncodedPixels'] == i].count().iloc[0]\n    count_img_to_ships[i] = temp_count\n\ncount_img_to_ships = pd.DataFrame(list(count_img_to_ships.items()), columns=['ShipCount', 'ImageCount'])\ncount_img_to_ships","metadata":{"execution":{"iopub.status.busy":"2024-05-19T21:58:34.45382Z","iopub.status.idle":"2024-05-19T21:58:34.454125Z","shell.execute_reply.started":"2024-05-19T21:58:34.453973Z","shell.execute_reply":"2024-05-19T21:58:34.453986Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"total_img_with_ships = count_img_to_ships['ImageCount'].sum() - 150_000\ntotal_img_with_ships","metadata":{"execution":{"iopub.status.busy":"2024-05-19T21:58:34.455735Z","iopub.status.idle":"2024-05-19T21:58:34.456062Z","shell.execute_reply.started":"2024-05-19T21:58:34.455897Z","shell.execute_reply":"2024-05-19T21:58:34.455911Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\nplt.bar(count_img_to_ships['ShipCount'], count_img_to_ships['ImageCount'], edgecolor='black')\nplt.xlabel('img_count')\nplt.ylabel('ships')\nplt.grid(True)\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2024-05-19T21:58:34.4573Z","iopub.status.idle":"2024-05-19T21:58:34.457677Z","shell.execute_reply.started":"2024-05-19T21:58:34.457508Z","shell.execute_reply":"2024-05-19T21:58:34.457523Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\nplt.bar(count_img_to_ships['ShipCount'], count_img_to_ships['ImageCount'], edgecolor='black')\nplt.xlabel('img_count')\nplt.ylabel('ships')\nplt.ylim(0, 10_000)\nplt.grid(True)\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2024-05-19T21:58:34.459181Z","iopub.status.idle":"2024-05-19T21:58:34.459537Z","shell.execute_reply.started":"2024-05-19T21:58:34.459347Z","shell.execute_reply":"2024-05-19T21:58:34.459376Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"wout_ships = df[df['EncodedPixels'].isna()]\nwith_ships = df[df['EncodedPixels'].notna()]\n\nreduced_wout_ships = wout_ships.sample(1500) \n\nbalanced_df = pd.concat([with_ships, reduced_wout_ships])\nbalanced_df","metadata":{"execution":{"iopub.status.busy":"2024-05-19T21:58:34.460846Z","iopub.status.idle":"2024-05-19T21:58:34.461185Z","shell.execute_reply.started":"2024-05-19T21:58:34.461018Z","shell.execute_reply":"2024-05-19T21:58:34.461033Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"balanced_df['EncodedPixels'] = balanced_df['EncodedPixels'].astype(str)","metadata":{"execution":{"iopub.status.busy":"2024-05-19T21:58:34.462194Z","iopub.status.idle":"2024-05-19T21:58:34.462534Z","shell.execute_reply.started":"2024-05-19T21:58:34.462346Z","shell.execute_reply":"2024-05-19T21:58:34.462377Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"balanced_grouped = balanced_df.groupby('ImageId')['EncodedPixels'].apply(lambda x: x.tolist()).reset_index()\nbalanced_grouped","metadata":{"execution":{"iopub.status.busy":"2024-05-19T21:58:34.463815Z","iopub.status.idle":"2024-05-19T21:58:34.46414Z","shell.execute_reply.started":"2024-05-19T21:58:34.463973Z","shell.execute_reply":"2024-05-19T21:58:34.463986Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"grouped = balanced_grouped.groupby(balanced_grouped['EncodedPixels'].apply(lambda x: x == ['nan']))\n\nnan_group = grouped.filter(lambda x: x['EncodedPixels'].iloc[0] == ['nan'])\nnot_nan_group = grouped.filter(lambda x: x['EncodedPixels'].iloc[0] != ['nan'])\n\nreduced_not_nan_group = not_nan_group.sample(5_000)\n\nrebalanced_grouped = pd.concat([reduced_not_nan_group, nan_group])\nrebalanced_grouped","metadata":{"execution":{"iopub.status.busy":"2024-05-19T21:58:34.465334Z","iopub.status.idle":"2024-05-19T21:58:34.465696Z","shell.execute_reply.started":"2024-05-19T21:58:34.465535Z","shell.execute_reply":"2024-05-19T21:58:34.465549Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class ShipDataset(Dataset):\n    def __init__(self, df, image_dir, image_shape=(768,768), transform=None, preprocessing_fn=None):\n        self.df = df\n        self.image_dir = image_dir\n        self.shape = image_shape\n        self.transform = transform\n        self.preprocessing_fn = preprocessing_fn\n    \n    def __len__(self):\n        return len(self.df)\n    \n    def __getitem__(self, idx):\n        image_name = self.df.iloc[idx]['ImageId']\n        image_path = os.path.join(self.image_dir, image_name)\n        image = Image.open(image_path)\n        \n        rles = self.df.iloc[idx]['EncodedPixels']\n        mask = self.combine_rle_masks(rles, self.shape)\n\n        if self.transform:\n            image = self.transform(image)\n        if self.preprocessing_fn:\n            image = self.preprocessing_fn(np.array(image))\n        \n        return image, mask\n    \n\n    def rle_to_mask(self, rle, shape):\n        \"\"\"\n        converting RLE string into a mask.\n\n        Parameters:\n        rle (str): rle string (format \"start1 length1 start2 length2 ...\")\n        shape (tuple): mask shape (height, width)\n\n        Returns:\n        numpy.ndarray: mask as 2D numpy array\n        \"\"\"\n            \n        mask = np.zeros(shape[0]*shape[1], dtype=np.uint8)\n\n        if rle == 'nan':\n            return mask.reshape(shape)\n\n        rle_nums = list(map(int, rle.split()))\n\n        starts = rle_nums[0::2]\n        lengths = rle_nums[1::2]\n\n        starts = [start -1  for start in starts]\n\n        for start, length in zip(starts, lengths):\n            mask[start:start + length] = 1\n\n        return mask.reshape(shape).T\n\n    def combine_rle_masks(self, rles, shape):\n        \"\"\"\n        Combines several RLE masks into one.\n\n        Parameters:\n        rles (list of str): list of rle strings\n        shape (tuple): mask shape (height, width)\n\n        Returns:\n        torch.Tensor: combined mask as a 2D tensor\n        \"\"\"\n        combined_mask = np.zeros(shape, dtype=np.uint8)\n\n        for rle in rles:\n            mask = self.rle_to_mask(rle, shape)\n            combined_mask = np.maximum(combined_mask, mask)\n            \n        tensor_combined_mask = torch.tensor(combined_mask, dtype=torch.uint8)\n\n        return tensor_combined_mask\n    \n   ","metadata":{"execution":{"iopub.status.busy":"2024-05-19T21:58:34.467563Z","iopub.status.idle":"2024-05-19T21:58:34.467887Z","shell.execute_reply.started":"2024-05-19T21:58:34.467713Z","shell.execute_reply":"2024-05-19T21:58:34.467726Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"visualize_dataset =  ShipDataset(df=rebalanced_grouped, image_dir=img_dir)","metadata":{"execution":{"iopub.status.busy":"2024-05-19T21:58:34.469022Z","iopub.status.idle":"2024-05-19T21:58:34.469359Z","shell.execute_reply.started":"2024-05-19T21:58:34.469193Z","shell.execute_reply":"2024-05-19T21:58:34.469207Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"unique_image_ids = rebalanced_grouped['ImageId'].unique()","metadata":{"execution":{"iopub.status.busy":"2024-05-19T21:58:34.47047Z","iopub.status.idle":"2024-05-19T21:58:34.470784Z","shell.execute_reply.started":"2024-05-19T21:58:34.470626Z","shell.execute_reply":"2024-05-19T21:58:34.470639Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_ids, test_ids = train_test_split(unique_image_ids, train_size=0.8, random_state=42)\n\ntrain_df = rebalanced_grouped[rebalanced_grouped['ImageId'].isin(train_ids)]\ntest_df = rebalanced_grouped[rebalanced_grouped['ImageId'].isin(test_ids)]\n\ntrain_grouped = train_df.groupby('ImageId')['EncodedPixels'].apply(lambda x: x.tolist()).reset_index()\ntest_grouped = test_df.groupby('ImageId')['EncodedPixels'].apply(lambda x: x.tolist()).reset_index()\n\ntrain_grouped.columns = ['ImageId', 'EncodedPixels']\ntest_grouped.columns = ['ImageId', 'EncodedPixels']","metadata":{"execution":{"iopub.status.busy":"2024-05-19T21:58:34.471966Z","iopub.status.idle":"2024-05-19T21:58:34.472277Z","shell.execute_reply.started":"2024-05-19T21:58:34.472122Z","shell.execute_reply":"2024-05-19T21:58:34.472135Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#избавление от ненужной размерности\ntrain_grouped['EncodedPixels'] = train_grouped['EncodedPixels'].apply(lambda x: [item for sublist in x for item in sublist])\ntest_grouped['EncodedPixels'] = test_grouped['EncodedPixels'].apply(lambda x: [item for sublist in x for item in sublist])","metadata":{"execution":{"iopub.status.busy":"2024-05-19T21:58:34.473649Z","iopub.status.idle":"2024-05-19T21:58:34.473984Z","shell.execute_reply.started":"2024-05-19T21:58:34.473814Z","shell.execute_reply":"2024-05-19T21:58:34.473828Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_grouped['EncodedPixels'].iloc[6]","metadata":{"execution":{"iopub.status.busy":"2024-05-19T21:58:34.475322Z","iopub.status.idle":"2024-05-19T21:58:34.475696Z","shell.execute_reply.started":"2024-05-19T21:58:34.47553Z","shell.execute_reply":"2024-05-19T21:58:34.475544Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"preprocess = get_preprocessing_fn('resnet34', pretrained='imagenet')\n\ntrain_dataset = ShipDataset(df=train_grouped, image_dir=img_dir, preprocessing_fn=preprocess)\ntest_dataset = ShipDataset(df=test_grouped, image_dir=img_dir, preprocessing_fn=preprocess)\n","metadata":{"execution":{"iopub.status.busy":"2024-05-19T21:58:34.47693Z","iopub.status.idle":"2024-05-19T21:58:34.477256Z","shell.execute_reply.started":"2024-05-19T21:58:34.477098Z","shell.execute_reply":"2024-05-19T21:58:34.477111Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for i in range(10):\n    image, mask = visualize_dataset[i]\n    if isinstance(image, torch.Tensor):\n        image = image.permute(1, 2, 0).numpy()\n    if isinstance(mask, torch.Tensor):\n        mask = mask.numpy()\n\n    plt.figure(figsize=(10, 5))  \n    plt.subplot(1, 2, 1)  \n    plt.imshow(image)  \n    plt.title(\"Image\")  \n    plt.axis(\"off\")  \n    \n    plt.subplot(1, 2, 2)  \n    plt.imshow(mask, cmap='gray')  \n    plt.title(\"Mask\")  \n    plt.axis(\"off\")  \n    plt.show()  ","metadata":{"execution":{"iopub.status.busy":"2024-05-19T21:58:34.478435Z","iopub.status.idle":"2024-05-19T21:58:34.478763Z","shell.execute_reply.started":"2024-05-19T21:58:34.478599Z","shell.execute_reply":"2024-05-19T21:58:34.478613Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"batch_size = 64\ntrain_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\ntest_loader = DataLoader(test_dataset, batch_size=batch_size)","metadata":{"execution":{"iopub.status.busy":"2024-05-19T21:58:34.480199Z","iopub.status.idle":"2024-05-19T21:58:34.480667Z","shell.execute_reply.started":"2024-05-19T21:58:34.480431Z","shell.execute_reply":"2024-05-19T21:58:34.480451Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = DeepLabV3Plus(encoder_name='resnet34', \n                      encoder_depth=5, \n                      encoder_weights='imagenet', \n                      encoder_output_stride=16, \n                      decoder_channels=256, \n                      decoder_atrous_rates=(12, 24, 36), \n                      in_channels=3, \n                      classes=1, \n                      activation='sigmoid', \n                      upsampling=4)\n\nmodel = model.to(device)\n\nfor param in model.encoder.parameters():\n    param.requires_grad = False","metadata":{"execution":{"iopub.status.busy":"2024-05-19T21:58:34.48194Z","iopub.status.idle":"2024-05-19T21:58:34.482255Z","shell.execute_reply.started":"2024-05-19T21:58:34.482098Z","shell.execute_reply":"2024-05-19T21:58:34.482111Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"summary(model, input_size=(3, 768, 768))","metadata":{"execution":{"iopub.status.busy":"2024-05-19T21:58:34.483425Z","iopub.status.idle":"2024-05-19T21:58:34.483776Z","shell.execute_reply.started":"2024-05-19T21:58:34.483604Z","shell.execute_reply":"2024-05-19T21:58:34.483619Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# @title train function\nimport time\n\ndef train_segmentation(model, optimizer, loss_fn, train_dl, val_dl, epochs=20, device='cpu'):\n    \"\"\"\n    Trains a segmentation model using Dice Loss and Recall as the evaluation metric.\n    \n    Parameters\n    ----------\n    model : nn.Module\n        The segmentation model to train.\n    optimizer : torch.optim.Optimizer\n        The optimizer to use for training.\n    loss_fn : nn.Module\n        The loss function to use for training (DiceLoss).\n    train_dl : DataLoader\n        DataLoader for the training dataset.\n    val_dl : DataLoader\n        DataLoader for the validation dataset.\n    epochs : int, optional\n        Number of epochs to train the model. Default is 20.\n    device : str, optional\n        The device to use for training ('cpu' or 'cuda'). Default is 'cpu'.\n    \n    Returns\n    -------\n    dict\n        Dictionary containing training and validation loss and recall for each epoch.\n    \"\"\"\n    \n    recall = torchmetrics.Recall(num_classes=1, threshold=0.5, task='binary').to(device)\n\n    history = {\n        'train_loss': [],\n        'val_loss': [],\n        'train_recall': [],\n        'val_recall': []\n    }\n    \n    start_time = time.time()\n    \n    for epoch in range(epochs):\n        model.train()\n        train_loss = 0.0\n        train_recall = 0.0\n        \n        for batch in train_dl:\n            images, masks = batch\n            images, masks = images.permute(0, 3, 1, 2).to(torch.float32).to(device), masks.to(device)\n            masks = masks.unsqueeze(1)\n            optimizer.zero_grad()\n            outputs = model(images)\n            loss = loss_fn(outputs, masks)\n            loss.backward()\n            optimizer.step()\n            \n            train_loss += loss.item() * images.size(0)\n            train_recall += recall(outputs, masks.int()).item() * images.size(0)\n        \n        train_loss /= len(train_dl.dataset)\n        train_recall /= len(train_dl.dataset)\n        \n        model.eval()\n        val_loss = 0.0\n        val_recall = 0.0\n        \n        with torch.no_grad():\n            for batch in val_dl:\n                images, masks = batch\n                images, masks = images.to(device), masks.to(device)\n                \n                outputs = model(images)\n                loss = loss_fn(outputs, masks)\n                \n                val_loss += loss.item() * images.size(0)\n                val_recall += recall(outputs, masks.int()).item() * images.size(0)\n        \n        val_loss /= len(val_dl.dataset)\n        val_recall /= len(val_dl.dataset)\n        \n        history['train_loss'].append(train_loss)\n        history['val_loss'].append(val_loss)\n        history['train_recall'].append(train_recall)\n        history['val_recall'].append(val_recall)\n        \n        print(f\"Epoch {epoch+1}/{epochs}, Train Loss: {train_loss:.4f}, Val Loss: {val_loss:.4f}, Train Recall: {train_recall:.4f}, Val Recall: {val_recall:.4f}\")\n\n    end_time = time.time()\n    total_time = end_time - start_time\n    print(f\"Training completed in {total_time:.2f} sec\")\n\n    return history","metadata":{"execution":{"iopub.status.busy":"2024-05-19T21:58:34.485287Z","iopub.status.idle":"2024-05-19T21:58:34.485675Z","shell.execute_reply.started":"2024-05-19T21:58:34.485507Z","shell.execute_reply":"2024-05-19T21:58:34.485522Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"loss_fn = DiceLoss(mode='binary')\noptimizer = torch.optim.Adam(model.parameters(), lr=1e-4)","metadata":{"execution":{"iopub.status.busy":"2024-05-19T21:58:34.486736Z","iopub.status.idle":"2024-05-19T21:58:34.487072Z","shell.execute_reply.started":"2024-05-19T21:58:34.486896Z","shell.execute_reply":"2024-05-19T21:58:34.486911Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"history = train_segmentation(model, optimizer, loss_fn, train_loader, test_loader, epochs=20, device=device)","metadata":{"execution":{"iopub.status.busy":"2024-05-19T21:58:34.48831Z","iopub.status.idle":"2024-05-19T21:58:34.488633Z","shell.execute_reply.started":"2024-05-19T21:58:34.488481Z","shell.execute_reply":"2024-05-19T21:58:34.488494Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def plot_metric(history, name):\n\n    plt.plot(history[name], label='train')\n    plt.plot(history['val_'+name], label='val')\n    plt.xlabel('Epoch')\n    plt.ylabel(name)\n    plt.title(f'{name.capitalize()} over Epochs')\n    plt.legend()\n    plt.show()\n","metadata":{"execution":{"iopub.status.busy":"2024-05-19T21:58:34.489732Z","iopub.status.idle":"2024-05-19T21:58:34.490028Z","shell.execute_reply.started":"2024-05-19T21:58:34.489873Z","shell.execute_reply":"2024-05-19T21:58:34.489885Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plot_metric(history, 'loss')","metadata":{"execution":{"iopub.status.busy":"2024-05-19T21:58:34.490838Z","iopub.status.idle":"2024-05-19T21:58:34.491126Z","shell.execute_reply.started":"2024-05-19T21:58:34.49098Z","shell.execute_reply":"2024-05-19T21:58:34.490992Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plot_metric(history, 'recall')","metadata":{"execution":{"iopub.status.busy":"2024-05-19T21:58:34.492397Z","iopub.status.idle":"2024-05-19T21:58:34.492699Z","shell.execute_reply.started":"2024-05-19T21:58:34.492551Z","shell.execute_reply":"2024-05-19T21:58:34.492563Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"torch.save(model, 'ship_segmentation_model.pth')","metadata":{"execution":{"iopub.status.busy":"2024-05-19T21:58:34.493771Z","iopub.status.idle":"2024-05-19T21:58:34.494068Z","shell.execute_reply.started":"2024-05-19T21:58:34.493919Z","shell.execute_reply":"2024-05-19T21:58:34.493931Z"},"trusted":true},"execution_count":null,"outputs":[]}]}