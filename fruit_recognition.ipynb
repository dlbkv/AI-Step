{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":3866368,"sourceType":"datasetVersion","datasetId":849073}],"dockerImageVersionId":30684,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"source":"<a href=\"https://www.kaggle.com/code/dlbkvv/fruit-recognition?scriptVersionId=172384971\" target=\"_blank\"><img align=\"left\" alt=\"Kaggle\" title=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"></a>","metadata":{},"cell_type":"markdown"},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd \nimport os\nimport torch\nfrom torchvision import datasets, transforms\ndevice = 'cuda' if torch.cuda.is_available() else 'cpu'","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-04-16T22:34:15.198621Z","iopub.execute_input":"2024-04-16T22:34:15.199021Z","iopub.status.idle":"2024-04-16T22:34:18.799714Z","shell.execute_reply.started":"2024-04-16T22:34:15.198978Z","shell.execute_reply":"2024-04-16T22:34:18.79863Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"from PIL import Image\n\nclass CustomImageDataset(torch.utils.data.Dataset):\n    def __init__(self, data_dir, transform=None):\n        self.data_dir = data_dir\n        self.transform = transform\n        \n        # Получаем список папок (классов)\n        self.classes = sorted(os.listdir(data_dir))\n        \n        # Создаем словарь, где ключ - это название класса, а значение - это его порядковый номер (метка)\n        self.class_to_label = {class_name: i for i, class_name in enumerate(self.classes)}\n        \n        # Получаем список всех файлов с изображениями и их соответствующие метки\n        self.samples = self.load_samples()\n    \n    def __len__(self):\n        return len(self.samples)\n\n    def __getitem__(self, idx):\n        img_path, label = self.samples[idx]\n        image = Image.open(img_path)\n        if self.transform:\n            image = self.transform(image)\n        return image, label\n    \n    def load_samples(self):\n        samples = []\n        \n        for class_ in self.classes:\n            class_path = os.path.join(self.data_dir, class_)\n            image_files = os.listdir(class_path)\n            for image_file in image_files:\n                image_path = os.path.join(class_path, image_file)\n                samples.append((image_path, self.class_to_label[class_]))\n        return samples        ","metadata":{"execution":{"iopub.status.busy":"2024-04-16T22:34:18.801668Z","iopub.execute_input":"2024-04-16T22:34:18.802228Z","iopub.status.idle":"2024-04-16T22:34:18.810942Z","shell.execute_reply.started":"2024-04-16T22:34:18.80219Z","shell.execute_reply":"2024-04-16T22:34:18.810231Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"class TransformDataset(torch.utils.data.Dataset):\n    def __init__(self, subset, transform=None):\n        self.subset = subset\n        self.transform = transform\n\n    def __getitem__(self, index):\n        x, y = self.subset[index]\n        if self.transform:\n            x = self.transform(x)\n        return x, y\n\n    def __len__(self):\n        return len(self.subset)\n","metadata":{"execution":{"iopub.status.busy":"2024-04-16T22:34:20.915738Z","iopub.execute_input":"2024-04-16T22:34:20.916163Z","iopub.status.idle":"2024-04-16T22:34:20.922824Z","shell.execute_reply.started":"2024-04-16T22:34:20.916119Z","shell.execute_reply":"2024-04-16T22:34:20.921615Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"train_transform = transforms.Compose([\n    transforms.Resize((100,100)),\n    transforms.RandomHorizontalFlip(p=0.5),\n    transforms.RandomVerticalFlip(p=0.5),\n    transforms.ToTensor(),\n])\ntest_transform = transforms.Compose([\n    transforms.Resize((100,100)),\n    transforms.ToTensor(),\n])\n\ndataset = CustomImageDataset(data_dir='/kaggle/input/fruit-recognition/train/train')\n","metadata":{"execution":{"iopub.status.busy":"2024-04-16T22:34:22.943114Z","iopub.execute_input":"2024-04-16T22:34:22.943732Z","iopub.status.idle":"2024-04-16T22:34:26.823313Z","shell.execute_reply.started":"2024-04-16T22:34:22.943703Z","shell.execute_reply":"2024-04-16T22:34:26.822378Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"from torch.utils.data import random_split\n\ntrain_ratio = 0.8\ntrain_dataset, val_dataset = random_split(dataset, [train_ratio, 1-train_ratio])","metadata":{"execution":{"iopub.status.busy":"2024-04-16T22:34:26.824903Z","iopub.execute_input":"2024-04-16T22:34:26.825216Z","iopub.status.idle":"2024-04-16T22:34:26.85365Z","shell.execute_reply.started":"2024-04-16T22:34:26.825193Z","shell.execute_reply":"2024-04-16T22:34:26.85236Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"train_dataset = TransformDataset(train_dataset, transform = train_transform)\nval_dataset = TransformDataset(val_dataset, transform = test_transform)","metadata":{"execution":{"iopub.status.busy":"2024-04-16T22:34:26.855089Z","iopub.execute_input":"2024-04-16T22:34:26.855408Z","iopub.status.idle":"2024-04-16T22:34:26.859474Z","shell.execute_reply.started":"2024-04-16T22:34:26.855379Z","shell.execute_reply":"2024-04-16T22:34:26.8585Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"batch_size = 512\ntrain_loader = torch.utils.data.DataLoader(train_dataset, shuffle=True, batch_size=batch_size)\nval_loader = torch.utils.data.DataLoader(val_dataset, shuffle=True, batch_size=batch_size)","metadata":{"execution":{"iopub.status.busy":"2024-04-16T22:34:27.12109Z","iopub.execute_input":"2024-04-16T22:34:27.121449Z","iopub.status.idle":"2024-04-16T22:34:27.12866Z","shell.execute_reply.started":"2024-04-16T22:34:27.121422Z","shell.execute_reply":"2024-04-16T22:34:27.127521Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"from torchvision.utils import make_grid\nimport matplotlib.pyplot as plt\n\nloader = torch.utils.data.DataLoader(train_dataset, shuffle=True, batch_size=32)\n\nbatch, labels = next(iter(loader))\n\ngrid = make_grid(batch).permute(1, 2, 0)\n\nplt.imshow(grid)","metadata":{"execution":{"iopub.status.busy":"2024-04-16T22:33:44.913654Z","iopub.status.idle":"2024-04-16T22:33:44.914154Z","shell.execute_reply.started":"2024-04-16T22:33:44.913886Z","shell.execute_reply":"2024-04-16T22:33:44.913907Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from torch import nn\nimport torch.nn.functional as F\n\nclass FruitClassifier(nn.Module):\n    def __init__(self, num_classes=33):\n        super().__init__()\n\n        self.conv1 = nn.Conv2d(in_channels=3, out_channels=8, kernel_size=3)\n        self.conv2 = nn.Conv2d(in_channels=8, out_channels=16, kernel_size=3)\n        self.conv3 = nn.Conv2d(in_channels=16, out_channels=16, kernel_size=3)\n        self.conv4 = nn.Conv2d(in_channels=16, out_channels=16, kernel_size=3)\n        self.conv5 = nn.Conv2d(in_channels=16, out_channels=16, kernel_size=3)\n        self.conv6 = nn.Conv2d(in_channels=16, out_channels=16, kernel_size=3)\n        self.conv7 = nn.Conv2d(in_channels=16, out_channels=8, kernel_size=1)\n\n        self.pool1 = nn.MaxPool2d(kernel_size=2, stride=2)\n        self.pool2 = nn.MaxPool2d(kernel_size=2, stride=2)\n        self.pool3 = nn.MaxPool2d(kernel_size=2, stride=2)\n\n        self.flatten = nn.Flatten()\n\n        self.linear1 = nn.Linear(8*8*8, 128)\n        self.linear2 = nn.Linear(128, num_classes)\n    \n    def forward(self, x):\n        # x - (batch, 1, 100, 100)\n        out = self.conv1(x) # (batch, 8, 98, 98)\n        out = F.relu(out)\n        \n        out = self.conv2(out) # (batch, 16, 96, 96)\n        out = F.relu(out)\n        \n        out = self.pool1(out) # (batch, 16, 48, 48)\n        \n        out = self.conv3(out) # (batch, 16, 46, 46)\n        out = F.relu(out)\n        \n        out = self.conv4(out) # (batch, 16, 44, 44)\n        out = F.relu(out)\n        \n        out = self.pool2(out) # (batch, 16, 22, 22)\n        \n        out = self.conv5(out) # (batch, 16, 20, 20)\n        out = F.relu(out)\n        \n        out = self.pool3(out) # (batch, 16, 10, 10)\n        \n        out = self.conv6(out) # (batch, 16, 8, 8)\n        out = F.relu(out)\n        \n        \n        out = self.conv7(out) # (batch, 8, 8, 8)\n        out = F.relu(out)\n        \n        out = self.flatten(out) # (batch, 8*8*8)\n        \n        out = self.linear1(out)\n        out = F.relu(out)\n\n        out = self.linear2(out)\n        #out = F.softmax(out, dim=-1)\n        return out\n\n\n    def predict(self, X, device='cpu'):\n        X = torch.FloatTensor(np.array(X)).to(device)\n\n        with torch.no_grad():\n            y_pred = F.softmax(self.forward(X), dim=-1)\n\n        return y_pred.cpu().numpy()\n\n\nmodel = FruitClassifier(len(dataset.classes)).to(device)\nmodel","metadata":{"execution":{"iopub.status.busy":"2024-04-16T22:34:28.543382Z","iopub.execute_input":"2024-04-16T22:34:28.54412Z","iopub.status.idle":"2024-04-16T22:34:28.58827Z","shell.execute_reply.started":"2024-04-16T22:34:28.544089Z","shell.execute_reply":"2024-04-16T22:34:28.587284Z"},"trusted":true},"execution_count":11,"outputs":[{"execution_count":11,"output_type":"execute_result","data":{"text/plain":"FruitClassifier(\n  (conv1): Conv2d(3, 8, kernel_size=(3, 3), stride=(1, 1))\n  (conv2): Conv2d(8, 16, kernel_size=(3, 3), stride=(1, 1))\n  (conv3): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1))\n  (conv4): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1))\n  (conv5): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1))\n  (conv6): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1))\n  (conv7): Conv2d(16, 8, kernel_size=(1, 1), stride=(1, 1))\n  (pool1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n  (pool2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n  (pool3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n  (flatten): Flatten(start_dim=1, end_dim=-1)\n  (linear1): Linear(in_features=512, out_features=128, bias=True)\n  (linear2): Linear(in_features=128, out_features=33, bias=True)\n)"},"metadata":{}}]},{"cell_type":"code","source":"!pip install -q torchsummary","metadata":{"execution":{"iopub.status.busy":"2024-04-14T23:42:54.243314Z","iopub.execute_input":"2024-04-14T23:42:54.243603Z","iopub.status.idle":"2024-04-14T23:43:08.128624Z","shell.execute_reply.started":"2024-04-14T23:42:54.243579Z","shell.execute_reply":"2024-04-14T23:43:08.127506Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from torchsummary import summary\n\nsummary(model, input_size=(3, 100, 100))","metadata":{"execution":{"iopub.status.busy":"2024-04-14T23:43:08.130023Z","iopub.execute_input":"2024-04-14T23:43:08.130333Z","iopub.status.idle":"2024-04-14T23:43:08.956113Z","shell.execute_reply.started":"2024-04-14T23:43:08.130304Z","shell.execute_reply":"2024-04-14T23:43:08.955108Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"loss_fn = nn.CrossEntropyLoss()\noptimizer = torch.optim.Adam(model.parameters(), lr=1e-3)","metadata":{"execution":{"iopub.status.busy":"2024-04-16T22:34:33.151898Z","iopub.execute_input":"2024-04-16T22:34:33.152298Z","iopub.status.idle":"2024-04-16T22:34:33.158496Z","shell.execute_reply.started":"2024-04-16T22:34:33.152267Z","shell.execute_reply":"2024-04-16T22:34:33.157484Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"# @title Функція для тренування\nimport time\n\ndef train(model, optimizer, loss_fn, train_dl, val_dl,\n          metrics=None, metrics_name=None, epochs=20, device='cpu', task='regression'):\n    '''\n    Runs training loop for classification problems. Returns Keras-style\n    per-epoch history of loss and accuracy over training and validation data.\n\n    Parameters\n    ----------\n    model : nn.Module\n        Neural network model\n    optimizer : torch.optim.Optimizer\n        Search space optimizer (e.g. Adam)\n    loss_fn :\n        Loss function (e.g. nn.CrossEntropyLoss())\n    train_dl :\n        Iterable dataloader for training data.\n    val_dl :\n        Iterable dataloader for validation data.\n    metrics: list\n        List of sklearn metrics functions to be calculated\n    metrics_name: list\n        List of matrics names\n    epochs : int\n        Number of epochs to run\n    device : string\n        Specifies 'cuda' or 'cpu'\n    task : string\n        type of problem. It can be regression, binary or multiclass\n\n    Returns\n    -------\n    Dictionary\n        Similar to Keras' fit(), the output dictionary contains per-epoch\n        history of training loss, training accuracy, validation loss, and\n        validation accuracy.\n    '''\n\n    print('train() called: model=%s, opt=%s(lr=%f), epochs=%d, device=%s\\n' % \\\n          (type(model).__name__, type(optimizer).__name__,\n           optimizer.param_groups[0]['lr'], epochs, device))\n\n    metrics = metrics if metrics else []\n    metrics_name = metrics_name if metrics_name else [metric.__name__ for metric in metrics]\n\n    history = {} # Collects per-epoch loss and metrics like Keras' fit().\n    history['loss'] = []\n    history['val_loss'] = []\n    for name in metrics_name:\n        history[name] = []\n        history[f'val_{name}'] = []\n\n    start_time_train = time.time()\n\n    for epoch in range(epochs):\n\n        # --- TRAIN AND EVALUATE ON TRAINING SET -----------------------------\n        start_time_epoch = time.time()\n\n        model.train()\n        history_train = {name: 0 for name in ['loss']+metrics_name}\n\n        for batch in train_dl:\n            x    = batch[0].to(device)\n            y    = batch[1].to(device)\n            y_pred = model(x)\n            loss = loss_fn(y_pred, y)\n\n            optimizer.zero_grad()\n            loss.backward()\n            optimizer.step()\n\n            y_pred = y_pred.detach().cpu().numpy()\n            y = y.detach().cpu().numpy()\n\n\n            history_train['loss'] += loss.item() * x.size(0)\n            for name, func in zip(metrics_name, metrics):\n                try:\n                    history_train[name] += func(y, y_pred) * x.size(0)\n                except:\n                    if task == 'binary': y_pred_ = y_pred.round()\n                    elif task == 'multiclass': y_pred_ = y_pred.argmax(axis=-1)\n                    history_train[name] += func(y, y_pred_) * x.size(0)\n\n        for name in history_train:\n            history_train[name] /= len(train_dl.dataset)\n\n\n        # --- EVALUATE ON VALIDATION SET -------------------------------------\n        model.eval()\n        history_val = {'val_' + name: 0 for name in metrics_name+['loss']}\n\n        with torch.no_grad():\n            for batch in val_dl:\n                x    = batch[0].to(device)\n                y    = batch[1].to(device)\n                y_pred = model(x)\n                loss = loss_fn(y_pred, y)\n\n                y_pred = y_pred.cpu().numpy()\n                y = y.cpu().numpy()\n\n                history_val['val_loss'] += loss.item() * x.size(0)\n                for name, func in zip(metrics_name, metrics):\n                    try:\n                        history_val['val_'+name] += func(y, y_pred) * x.size(0)\n                    except:\n                        if task == 'binary': y_pred_ = y_pred.round()\n                        elif task == 'multiclass': y_pred_ = y_pred.argmax(axis=-1)\n\n                        history_val['val_'+name] += func(y, y_pred_) * x.size(0)\n\n        for name in history_val:\n            history_val[name] /= len(val_dl.dataset)\n\n        # PRINTING RESULTS\n\n        end_time_epoch = time.time()\n\n        for name in history_train:\n            history[name].append(history_train[name])\n            history['val_'+name].append(history_val['val_'+name])\n\n        total_time_epoch = end_time_epoch - start_time_epoch\n\n        print(f'Epoch {epoch+1:4d} {total_time_epoch:4.0f}sec', end='\\t')\n        for name in history_train:\n            print(f'{name}: {history[name][-1]:10.3g}', end='\\t')\n            print(f\"val_{name}: {history['val_'+name][-1]:10.3g}\", end='\\t')\n        print()\n\n    # END OF TRAINING LOOP\n\n    end_time_train       = time.time()\n    total_time_train     = end_time_train - start_time_train\n    print()\n    print('Time total:     %5.2f sec' % (total_time_train))\n\n    return history","metadata":{"execution":{"iopub.status.busy":"2024-04-16T22:34:38.572325Z","iopub.execute_input":"2024-04-16T22:34:38.57273Z","iopub.status.idle":"2024-04-16T22:34:38.591939Z","shell.execute_reply.started":"2024-04-16T22:34:38.572701Z","shell.execute_reply":"2024-04-16T22:34:38.590873Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import accuracy_score\n\nhistory = train(model, optimizer, loss_fn, train_loader, val_loader,\n               epochs=20, \n               metrics=[accuracy_score],\n               device=device,\n               task='multiclass')","metadata":{"execution":{"iopub.status.busy":"2024-04-14T23:43:08.989446Z","iopub.execute_input":"2024-04-14T23:43:08.98971Z","iopub.status.idle":"2024-04-14T23:52:31.173921Z","shell.execute_reply.started":"2024-04-14T23:43:08.989678Z","shell.execute_reply":"2024-04-14T23:52:31.172971Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def plot_metric(history, name):\n    plt.title(f\"Model results with {name}\")\n    plt.plot(history[name], label='train')\n    plt.plot(history['val_'+name], label='val')\n    plt.xlabel('Epoch')\n    plt.ylabel(name)\n    plt.legend()\n\n\nplot_metric(history, 'loss')","metadata":{"execution":{"iopub.status.busy":"2024-04-14T23:52:31.175387Z","iopub.execute_input":"2024-04-14T23:52:31.176074Z","iopub.status.idle":"2024-04-14T23:52:31.526457Z","shell.execute_reply.started":"2024-04-14T23:52:31.176036Z","shell.execute_reply":"2024-04-14T23:52:31.525532Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plot_metric(history, 'accuracy_score')","metadata":{"execution":{"iopub.status.busy":"2024-04-14T23:52:31.527644Z","iopub.execute_input":"2024-04-14T23:52:31.527951Z","iopub.status.idle":"2024-04-14T23:52:31.854729Z","shell.execute_reply.started":"2024-04-14T23:52:31.527906Z","shell.execute_reply":"2024-04-14T23:52:31.853812Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import ConfusionMatrixDisplay\n\nmodel = model.to('cpu')  # відключаємо від gpu\n\nloader = torch.utils.data.DataLoader(val_dataset, batch_size=len(val_dataset))\nX_test, y_test = next(iter(loader))\n\ny_pred = model.predict(X_test)\n\nConfusionMatrixDisplay.from_predictions(y_test, y_pred.argmax(-1), display_labels=dataset.classes)\nplt.xticks(rotation=90)\nplt.plot()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}